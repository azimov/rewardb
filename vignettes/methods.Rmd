---
title: "REWARD Methods Overview"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{data-build}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction and overall workflow
This document aims to describe the broad technical aspects of REWARD, though ignores some technical implementation specifics.
REWARD  has several core components to its workflow:

* Construction of cohort references
* Generation of cohorts
* Generation of Incident Rate Ratios (IRR) values from Self-Controlled Cohort study design (SCC)
* Post-processing meta-analysis and Empirical Calibration

TODO: REWARD has protocol approval within JNJ for the process (and other study designs not discussed or currently used). When making changes amendments to this protocol may be needed, consult this document before doing so. [Link to REWARD protocol document](http://TODO.jnj.com).

## Databases used
The databases currently approved for use in reward are:

* IBM CCAE
* IBM MDCD
* IBM MDCR
* Optum
* Pharmetrics

The UK CPRD is currently under protocol review and results from this cannot be published until it has been accepted. To date, no data have been generated from the CPRD cdm.

# REWARD cohorts
Most cohorts used in REWARD (particularly those for negative controls) are automatically constructed from the vocabulary using the condition_era, condition_occurence, drug_era and drug_exposure tables from the CDM.
The outcome cohorts used are based on Standard SNOMED concepts from the OMOP vocabulary.
Similarly, RXNorm ingredients are the main basis for exposure cohorts.

As references can change between different versions the cohorts are uniquely identified on REWARD's central server constructed from a vocabulary there.
This resolves issues related to the individual differences between cdm vocabularies but requires the entire set of REWARD references to be imported into the CDMs before computation can take place.

Before cohorts are run on the CDMs the references must, therefore, be inserted into the REWARD postgres schema.
It is possible to do this on an ad-hoc basis (e.g. with added ATLAS cohorts) but these references must then be inserted into the CDM again.
To maintain referential integrity these references must be imported and exported between versions.
For example, if an ATLAS cohort is updated the old reference is removed and a new REWARD id is created.

## Exposures

There are, currently, 3 methods for the construction of exposure cohorts.
Automated ingredient and ATC exposures, atlas exposures and custom exposure classes that look at groupings of ingredients that are not captured at the ATC level.

### Ingredient and ATC exposures
Ingredient exposure cohorts are generated by looking up RXNorm ingredient concepts in the drug era table.
For ATC class level exposures a patient prescribed any ingredient under this classification are included.
An exposure window will be merged based on these drugs, even if the specific ingredient a patient takes changes during that window, because it is in the same classification they will be merged..
This is currently ATC class 4 only and not broader ATC 3 or ATC 2 groupings (ATC 5 being equivalent to RXNorm ingredients).

See `createCohorts.sql` for the exact created cohorts.

### Custom exposure groupings
For some categories of drug it is desirable to classify them together (for example, IL-17 inhibitors are not an ATC level 4 grouping).
Custom groupings work identically to the ATC level 4 groupings described above.

See `addCustomExposureCohorts.sql` for the implementation.

### Atlas Exposures
It is also possible to create exposures in ATLAS and have them ran for use in REWARD.
See the function definition `insertAtlasCohortRef` for more details on how to insert the reference into the main REWARD database.
They can be from any ATLAS instance, not just the JNJ specific instance.
This has been tested on WebAPI v2.8.

Note, when constructing vaccines an update to the ETL process removed CVX codes from the `drug_era` table.
When constructing vaccine cohorts both the `drug_era` and `drug_exposure` tables should be considered.

### Custom Drug Eras
Cohorts with non-standard drug eras can be constructed with customizable drug era periods.
For example, biologicals such as the IL-17 inhibitor Brodalumab, have non-standard and unique drug eras.
These exposures are computed in the `customDrugEra.sql` script and should be computed before exposure cohorts are created.
Though updates to this script are possible it, these are now considered legacy cohorts.
Where possible, ATLAS definitions of cohorts with non-standard exposure windows should be considered.

## Outcomes

### Automated outcomes
SNOMED condition concepts are used to find conditions in an automated manner.
These are any diagnosis code (type 0) and any inpatient stays (type 1).
Conditions must appear in the condition_occurence table but both methods require an visit in the visit occurrence table to be confirmed.

_Note, that these definitions are not to be included in open source packages and are JNJ commercial property until agreement on releasing them is agreed._

All cohorts must either be a descendant concept of the concept "Clinical Finding", 441840 with 2 levels of separation or in the set:

Concept ID          Concept Name
----------- ----------------------------
4299449	    Hematoma
40483532    Anasarca
4171917	    Localized edema
4145627	    Biliary calculus
192671	    Gastrointestinal hemorrhage
438555	    Cyanosis
434621	    Autoimmune disease
433595	    Edema
439847	    Intracranial hemorrhage
433736	    Obesity
441408	    Vomiting
72404	    Joint stiffness
76784	    Hemarthrosis
137977	    Jaundice
433778	    Orbital hemorrhage
375258	    Photokeratitis
434157	    Madelung's deformity
258449	    Hemopericardium
437312	    Bleeding
313878	    Respiratory symptom

Table: Condition concept sets that are exceptions to the > 2 levels of separation from "Clinical Finding" rule.

In addition cohort ancestors must not contain:

```
'%finding', 'disorder of%', 'finding of%', 'disease of%', 'injury of%', '%by site' , '%by body site', '%by mechanism', '%of body region', '%of anatomical site', '%of specific body structure%'.
```

These references are all created in `cohortReferences.sql`

This ancestor grouping generated on CDMs is found in the file `createOutcomeCohorts.sql`. _In the future, this file should be the same method used on the CDM and the REWARD postgres instance, to ensure that there are not two sources for generating this hierarchy._

The cohorts created here do not require any washout period.
However, this is included in exposure cohorts and can be modified in the `OHDSI/SelfControlledCohort` R package.
Note that most of these cohorts definitions will yield no patients in most CDMs.

#### Type 0 cohorts
Type 0 outcome cohorts refers to conditions which are referenced in the visit occurrence table and confirmed with two diagnosis codes on two unique dates that are any time apart.
It has been suggested that this criteria is inappropriate and that one diagnosis code is sufficient.
Similarly, the fact that the two dates are not the same could create some bias where the condition occurrence is a long time apart.
It is likely that this is necessary for cohorts in claims databases but not EHR datasets such as CPRD.

See `createType0OutcomeCohorts.sql` for more details.

#### Type 1 cohorts
Type 1 cohorts refer to inpatient visits, they require a condition from the concepts described above with a visit of type 9201 "Inpatient Visit".

See `createType1OutcomeCohorts.sql` for more details.

### ATLAS outcomes
As with exposure cohorts, ATLAS can be used to define cohorts they can then be imported into the Postgres database with the `insertAtlasCohortRef` function.
It is noteworthy that these cohorts to not actually need to be stored in ATLAS and cna just have a JSON definition. At some point [capr](https:://github.com/OHDSI/capr) definitions should be considered.

#### Phenotype Library
The entire [OHDSI Phenotype Library](https:://github.com/OHDSI/PhenotypeLibrary) is imported into REWARD by default using the develop branch.

## Issues with cohort construction on redshift
Currently, the cohort construction process on redshift often fails due to disk space errors.
A workaround has been to use a batch process that selects only around 5000 uncomputed cohorts, where computation is checked by looking at the cohort identifiers in the resulting cohort table.
However, this process is still prone to failure and often needs to be restarted manually.

The size of the tables in scratch space is unavoidably large, taking over 100 GB on some CDMs.

# Generating results

## Self-controlled cohort study design
Reward has protocol approval for Self-Controlled cohort, Self-controlled case series and comparative cohort designs.
Currently, only the self-controlled cohort design has been implemented and is preferable to comparative designs as allowing individuals to act as their own controls allows for the control of time-invariant bias within subjects.

Automated methods for comparative cohort designs should also be explored as they allow different questions to be asked.

## Exposure/outcome cohort statistics

For the self-controlled cohort study design additional statistics regarding the time on treatment and absolute time between exposure and outcome are calculated.
This distribution applies only to the time at risk windows for patients exposed to the treatment that have the outcome of interest.

Future work in to characterization of the exposure/outcome pairs should be conducted as this is likely important information (e.g. questions arise about the demographics of patients at the time of exposure/ when they experience the outcome).

## Meta-analysis
The `meta` r package is used to calculate meta-analysis across all databases.
Meta analysis is not performed until a study area dashboard is created, this is a post processing step.
It is not computationally intensive to compute meta-analysis for an individual exposure/outcome pair, but computing it accross the E * O set of exposures is time prohibative and not currently necessary.

## Empirical Calibration
The [`EmpiricalCalibration` OHDSI r package](https://github.com/OHDSI/EmpiricalCalibration/) is used to compute calibrated p-values and confidence intervals.
Using an automated negative control selection process allows the effect estimates to be adjusted according to the computed empirical null distribution.

### Negative control selection
Negative control selection is based around the Common Evidence Model (CEM) that uses spontaneous reports, literature data and labels to build a map of associations between ingredients and outcomes.
A matrix for all the ingredient and condition level associations is stored in the reward postgres instance.
This is an export from the CEM package and is stored in the table `cem.matrix_summary`.
Here a 1 indicates that an ingredient/outcome pair are related via some mechanism identified in the CEM, and 0 indicates that no known association has been found.

ATLAS exports of concept set evidence can also be imported into REWARD when dashboards are generated.
These will be applied in addition to the automated cohorts.
For example, the process my find no mappings - this is a simple work around to ensure that automated negative controls can be used.

Adding the `cemEvidenceFiles` option to a dashboard config file supports this, for example:

```
cemEvidenceFiles:
    13735: "extra/controls/influenza_vaccine_controls_export.csv"
    13734: "extra/controls/pneumenocccoal_vaccine_export.csv"
```

The process for automated negative control selection as been outlined as interesting to many other researchers and is currently under evaluation.